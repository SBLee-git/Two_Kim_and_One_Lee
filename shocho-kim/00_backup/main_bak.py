from fastapi import FastAPI
from pydantic import BaseModel
import torch
from transformers import GPT2LMHeadModel, AutoTokenizer
import os
import datetime
import random
import pandas as pd

# í˜„ì¬ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
now = datetime.datetime.now()
# ì‹œê°„ í˜•ì‹ ì§€ì • (ì˜ˆ: '2025-01-15_14-30-00')
timestamp = now.strftime("%Y-%m-%d_%H-%M-%S")
SAVE_PATH = f"../1.ë°ì´í„°ëª¨ìŒ/generated_lyrics/generated_lyrics_{timestamp}.txt"  # ì €ì¥í•  íŒŒì¼ ê²½ë¡œ

app = FastAPI()

# 1. GPU ì‚¬ìš© ì—¬ë¶€ í™•ì¸
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# 2. ì €ì¥ëœ GPT-2 ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
# /home/wanted-1/potenup-workspace/Project/project2/team5/2.í”„ë¡œì„¸ìŠ¤/fine_tuned_model
model = GPT2LMHeadModel.from_pretrained("../2.í”„ë¡œì„¸ìŠ¤/fine_tuned_model").to(device)
tokenizer = AutoTokenizer.from_pretrained("../2.í”„ë¡œì„¸ìŠ¤/fine_tuned_model")
model.to("cuda")
model.eval()  # í‰ê°€ ëª¨ë“œ ì „í™˜

# 3. ì…ë ¥ ë°ì´í„° ëª¨ë¸ ì •ì˜
class InputText(BaseModel):
    text: str

# 4. í…ìŠ¤íŠ¸ ìƒì„± ì—”ë“œí¬ì¸íŠ¸
@app.post("/generate/")
async def generate_text(data: InputText):
    prompt = data.text
    print(f"prompt >>>> : {prompt}")

    # ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¥¼ í† í°í™” ë° GPUë¡œ ì´ë™
    input_ids = tokenizer(prompt, return_tensors="pt").input_ids.to(device)

    # ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±
    output = model.generate(
        input_ids=input_ids,
        max_length=200,
        temperature=1.0,
        top_k=200,
        top_p=0.9,
        repetition_penalty=1.2,
        do_sample=True
    )

    # ìƒì„±ëœ í…ìŠ¤íŠ¸ ë””ì½”ë”©
    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)
    # generated_text = generated_text[:-1] 

    # ğŸµ ìƒì„±ëœ ê°€ì‚¬ë¥¼ íŒŒì¼ì— ì €ì¥
    with open(SAVE_PATH, "a", encoding="utf-8") as f:
        f.write(generated_text + "\n")

    return {"response": generated_text}

app2 = FastAPI()

### ê¸°ì¡´ ê°€ì‚¬ ë°ì´í„° ë¡œë“œ (ê³µë°± ë¬¸ì¥ ì œê±°)
df = pd.read_csv("../1.ë°ì´í„°ëª¨ìŒ/'music_data(Merge)'.csv")  # ê°€ì‚¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
df = df[['lyrics']].dropna()
df['sentences'] = df['lyrics'].apply(lambda x: [s.strip() for s in x.split("\n") if s.strip()])  # ê³µë°± ë¬¸ì¥ ì œê±°
lyrics_sentences = [sent for sublist in df['sentences'] for sent in sublist]

### ë¹„ë¬¸ ìƒì„± í•¨ìˆ˜
def shuffle_words(sentence):
    words = sentence.split()
    random.shuffle(words)
    return " ".join(words)

def remove_random_word(sentence):
    words = sentence.split()
    if len(words) > 1:
        words.pop(random.randint(0, len(words)-1))
    return " ".join(words)

### ëœë¤ ë¹„ë¬¸ ë°ì´í„° ìƒì„± (ê³µë°± ë¬¸ì¥ ë°©ì§€)
num_samples = 50  # í•œ ë²ˆì— ìƒì„±í•  ë¹„ë¬¸ ê°œìˆ˜
bad_sentences = []

for _ in range(num_samples):
    original = random.choice(lyrics_sentences)
    method = random.choice([shuffle_words, remove_random_word])
    generated = method(original).strip()

    # ì™„ì „íˆ ê³µë°±ì¸ ë¬¸ì¥ì€ ì €ì¥í•˜ì§€ ì•ŠìŒ
    if generated:
        bad_sentences.append({"original": original, "generated": generated})

### API ì—”ë“œí¬ì¸íŠ¸
@app.get("/get_sentences")
def get_sentences():
    """ë¹„ë¬¸ ë°ì´í„°ë¥¼ ë°˜í™˜ (ê³µë°± ë¬¸ì¥ ì œì™¸)"""
    return {"sentences": bad_sentences}

class LabelInput(BaseModel):
    original: str
    generated: str
    score: int  # ì •ìˆ˜ ì…ë ¥

labeled_data = []

@app.post("/submit_label")
def submit_label(label: LabelInput):
    """ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì •ìˆ˜ ì ìˆ˜ ì €ì¥"""
    labeled_data.append({"original": label.original, "generated": label.generated, "score": label.score})
    return {"message": "ë¼ë²¨ë§ ì™„ë£Œ!"}

@app.get("/get_labeled_data")
def get_labeled_data():
    """í˜„ì¬ê¹Œì§€ ë¼ë²¨ë§ëœ ë°ì´í„° í™•ì¸"""
    return {"labeled_data": labeled_data}
